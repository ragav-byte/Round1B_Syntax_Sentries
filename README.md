# Round1B_Syntax_Sentries

# ğŸ“„ Multi-Collection PDF Analyzer (Round 1B)

This project is built for **Round 1B** of a document intelligence challenge. It analyzes multiple PDF collections and generates structured, persona-specific JSON output based on relevance and document content.

---

## ğŸš€ Objective

To process 3â€“10 PDF documents per collection and extract **ranked and refined section-wise summaries** tailored to a given persona and job-to-be-done (JTBD). The system outputs a clean JSON with relevant section titles and contents.

---

## ğŸ“ Project Structure

```
Round1B/
â”‚
â”œâ”€â”€ inputs/
â”‚   â”œâ”€â”€ collections1/        # Folder of PDFs for collection 1
â”‚   â”œâ”€â”€ collections2/        # Folder of PDFs for collection 2
â”‚   â””â”€â”€ collections3/        # Folder of PDFs for collection 3
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.py             # Model logic to extract, rank and refine section content
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ output.json          # Final structured output
â”‚   â””â”€â”€ challenge1b_output_generated.json # Sample output file
â”‚
â”œâ”€â”€ Dockerfile               # Container setup to run the system offline
â”œâ”€â”€ requirements.txt         # Python package dependencies
â””â”€â”€ README.md                # Project overview (you're here!)
```

---

## ğŸ§  Key Features

- ğŸ” Extracts and ranks **top 5 relevant sections**
- ğŸ§© Merges content across PDFs within each collection
- ğŸ“‘ Structured **JSON output** for downstream processing
- ğŸ§  Persona + JTBD aware analysis
- ğŸ³ Runs offline in Docker, within 60s (CPU only)

---

## âš™ï¸ Setup Instructions

### ğŸ 1. Set up virtual environment
```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### ğŸ“¦ 2. Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ“‚ Input Format

Place the document collections inside the `inputs/` folder. Each collection should be a subfolder with 3â€“10 PDFs.

```
inputs/
â”œâ”€â”€ collections1/
â”œâ”€â”€ collections2/
â””â”€â”€ collections3/
```

---

## ğŸ§ª Running the Program

```bash
python models/model.py
```

It will:
- Read all PDFs in each collection
- Perform layout + content analysis
- Output a structured JSON to `output/output.json`

---

## ğŸ“Š Output Format

The output follows this structure:

```json
{
  "collection_name": "collections1",
  "persona": "Marketing Manager",
  "job_to_be_done": "Find relevant travel spots",
  "sections": [
    {
      "title": "Top 5 Coastal Adventures",
      "importance": 0.95,
      "content": "This section covers beaches and water sports ideal for tourists..."
    }
  ]
}
```

---

## ğŸ³ Run with Docker (Optional)

Change directory

```bash
cd MutliPDFExtracter-master
```

Docker command
```bash
docker build -t pdf-analyzer .

docker run `
  -e PDF_FOLDER=inputs/collections1/pdfs `
  -e INPUT_JSON=inputs/collections1/challenge1b_input.json `
  -e OUTPUT_JSON=output/challenge1b_output_generated.json `
  -v ${PWD}/inputs:/app/inputs `
  -v ${PWD}/output:/app/output `
  pdf-analyzer
```
To run different pdf collection
```bash

docker run `
  -e PDF_FOLDER=inputs/collections2/pdfs `
  -e INPUT_JSON=inputs/collections2/challenge1b_input.json `
  -e OUTPUT_JSON=output/challenge1b_output_generated.json `
  -v ${PWD}/inputs:/app/inputs `
  -v ${PWD}/output:/app/output `
  pdf-analyzer
```

-----
